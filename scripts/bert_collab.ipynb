{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"bert_collab.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lrf5HVIk8TDJ","executionInfo":{"status":"ok","timestamp":1607615388996,"user_tz":-60,"elapsed":776,"user":{"displayName":"François Michel","photoUrl":"","userId":"04680873055823462215"}},"outputId":"db184df2-05a0-4a4c-8fac-738330b9587a"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UIgPBbFE84Wo","executionInfo":{"status":"ok","timestamp":1607615389242,"user_tz":-60,"elapsed":994,"user":{"displayName":"François Michel","photoUrl":"","userId":"04680873055823462215"}}},"source":["import sys\n","sys.path.append('/content/drive/MyDrive/Colab Notebooks/ml-project2/scripts')"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xAHwyyMc9JVm","executionInfo":{"status":"ok","timestamp":1607615391605,"user_tz":-60,"elapsed":3350,"user":{"displayName":"François Michel","photoUrl":"","userId":"04680873055823462215"}},"outputId":"e778d035-3e88-43fc-d35c-79cc70ff0f96"},"source":["!pip install wordninja\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: wordninja in /usr/local/lib/python3.6/dist-packages (2.0.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V_64774i-BHL","executionInfo":{"status":"ok","timestamp":1607615405763,"user_tz":-60,"elapsed":17479,"user":{"displayName":"François Michel","photoUrl":"","userId":"04680873055823462215"}},"outputId":"9e808057-1d2a-4f4d-8d61-bed521d54774"},"source":["!pip install git+https://github.com/huggingface/transformers.git"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Collecting git+https://github.com/huggingface/transformers.git\n","  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-631x_two\n","  Running command git clone -q https://github.com/huggingface/transformers.git /tmp/pip-req-build-631x_two\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied (use --upgrade to upgrade): transformers==4.1.0.dev0 from git+https://github.com/huggingface/transformers.git in /usr/local/lib/python3.6/dist-packages\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==4.1.0.dev0) (4.41.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==4.1.0.dev0) (2019.12.20)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==4.1.0.dev0) (20.4)\n","Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers==4.1.0.dev0) (0.9.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==4.1.0.dev0) (2.23.0)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==4.1.0.dev0) (0.8)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==4.1.0.dev0) (1.18.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==4.1.0.dev0) (3.0.12)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers==4.1.0.dev0) (0.0.43)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==4.1.0.dev0) (2.4.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==4.1.0.dev0) (1.15.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==4.1.0.dev0) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==4.1.0.dev0) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==4.1.0.dev0) (2020.11.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==4.1.0.dev0) (3.0.4)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==4.1.0.dev0) (0.17.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==4.1.0.dev0) (7.1.2)\n","Building wheels for collected packages: transformers\n","  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for transformers: filename=transformers-4.1.0.dev0-cp36-none-any.whl size=1448361 sha256=1314e5fcc8db25acc603e54f67639302d01d410aff54da72d2ca7dca2bbf033c\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-13y0uwob/wheels/33/eb/3b/4bf5dd835e865e472d4fc0754f35ac0edb08fe852e8f21655f\n","Successfully built transformers\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ta526BAw7yTd","executionInfo":{"status":"ok","timestamp":1607615408534,"user_tz":-60,"elapsed":20239,"user":{"displayName":"François Michel","photoUrl":"","userId":"04680873055823462215"}},"outputId":"9cc5fb94-44c2-43ad-f7d9-692cc5a977a8"},"source":["from preprocess import preprocess\n","from bert import *\n","from data_processing import *\n","from helper import *\n","\n","import numpy as np\n","import torch\n","from transformers import BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n","from sklearn.model_selection import train_test_split"],"execution_count":5,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"y6w0-Q5kjWlb","executionInfo":{"status":"ok","timestamp":1607615408541,"user_tz":-60,"elapsed":20237,"user":{"displayName":"François Michel","photoUrl":"","userId":"04680873055823462215"}}},"source":["# Set all parameters :\n","SEED = 42\n","NUM_TRAIN_TWEETS = 100\n","BATCH_LEN = 20\n","TRAIN_EPOCHS = 1\n","TOKEN_LEN = 60  # the maximum is 512\n","RATIO_TRAIN = 0.8\n","LEARNING_RATE = 2e-5\n","EPSILON = 1e-8"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"RgeTR6tKgPLW","executionInfo":{"status":"ok","timestamp":1607615408542,"user_tz":-60,"elapsed":20233,"user":{"displayName":"François Michel","photoUrl":"","userId":"04680873055823462215"}}},"source":["# Set all the seeds\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed_all(SEED)\n","np.random.seed(SEED)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"MRYnrdiqgVZH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607615408543,"user_tz":-60,"elapsed":20227,"user":{"displayName":"François Michel","photoUrl":"","userId":"04680873055823462215"}},"outputId":"22ec153c-c6c7-43c0-9f8c-01c8709cb749"},"source":["# Select the best device available\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","device"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda', index=0)"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"TjsZxKCT7yTe","executionInfo":{"status":"ok","timestamp":1607615408543,"user_tz":-60,"elapsed":20218,"user":{"displayName":"François Michel","photoUrl":"","userId":"04680873055823462215"}}},"source":["path_to_tweets = '/content/drive/MyDrive/Colab Notebooks/ml-project2/data/twitter-datasets/'#'../data/twitter-datasets/'\n","pos_path = path_to_tweets + 'train_pos_full.txt'\n","neg_path = path_to_tweets + 'train_neg_full.txt'\n","test_path = path_to_tweets + 'test_data.txt'"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PkP5VAitRVR1"},"source":["## Prepare the training data"]},{"cell_type":"code","metadata":{"id":"Fe4UlVrc7yTe","executionInfo":{"status":"ok","timestamp":1607615621829,"user_tz":-60,"elapsed":641,"user":{"displayName":"François Michel","photoUrl":"","userId":"04680873055823462215"}}},"source":["# Load the training data\n","df_train = load_train(pos_path, neg_path, NUM_TRAIN_TWEETS)"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"16RGRgkdW5sd","executionInfo":{"status":"ok","timestamp":1607615656049,"user_tz":-60,"elapsed":579,"user":{"displayName":"François Michel","photoUrl":"","userId":"04680873055823462215"}},"outputId":"7ebd2bda-0f55-4139-bdab-b318d9959a38"},"source":["df_train.tweet."],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    <user> i dunno justin read my mention or not ....\n","0    vinco tresorpack 6 ( difficulty 10 of 10 objec...\n","Name: tweet, dtype: object"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"t5jVycd47yTf","executionInfo":{"status":"ok","timestamp":1607615408544,"user_tz":-60,"elapsed":20203,"user":{"displayName":"François Michel","photoUrl":"","userId":"04680873055823462215"}}},"source":["# Preprocess the training data\n","#out_pre_train = path_to_tweets + 'pre_train.csv'\n","#df_train = preprocess(df_train, out_pre_train)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"EK6PBVK97yTf","executionInfo":{"status":"ok","timestamp":1607615408890,"user_tz":-60,"elapsed":20543,"user":{"displayName":"François Michel","photoUrl":"","userId":"04680873055823462215"}}},"source":["# Tokenize the training data\n","out_token_train = path_to_tweets + 'token_train.csv'\n","df_train = bert_tokenize_train(df_train, out_token_train, max_len=TOKEN_LEN)"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uSEemCv-GA50"},"source":["## Create and train the model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5U4SnNqHUPjk","executionInfo":{"status":"ok","timestamp":1607615418202,"user_tz":-60,"elapsed":29847,"user":{"displayName":"François Michel","photoUrl":"","userId":"04680873055823462215"}},"outputId":"2b3a7972-b9dc-44c2-9251-b3f3cc4c7cf6"},"source":["# create the model\n","model = BertForSequenceClassification.from_pretrained('bert-base-uncased').to(device)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"2yF_Qmx9RVR2","executionInfo":{"status":"ok","timestamp":1607615418204,"user_tz":-60,"elapsed":29840,"user":{"displayName":"François Michel","photoUrl":"","userId":"04680873055823462215"}}},"source":["# split the data into a training set and a validation set\n","train, validation = train_test_split(df_train, train_size=RATIO_TRAIN, random_state=SEED)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"AxZWbBZcYegK","scrolled":true,"executionInfo":{"status":"ok","timestamp":1607615418204,"user_tz":-60,"elapsed":29830,"user":{"displayName":"François Michel","photoUrl":"","userId":"04680873055823462215"}}},"source":["# create the optimizer and the scheduler\n","optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, eps=EPSILON)\n","scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train)*TRAIN_EPOCHS)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"Eob3Ft19RVR3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607615420254,"user_tz":-60,"elapsed":31874,"user":{"displayName":"François Michel","photoUrl":"","userId":"04680873055823462215"}},"outputId":"8af3c8ef-8bbf-4715-a241-8228b5a3913f"},"source":["# train the model\n","fit_model(model, train, validation, BATCH_LEN, TRAIN_EPOCHS, optimizer, scheduler, device)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["  0%|          | 0/1 [00:00<?, ?it/s]\n","Transfer progress:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["epoch 0\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Transfer progress:  12%|█▎        | 1/8 [00:00<00:02,  2.77it/s]\u001b[A\n","Transfer progress:  25%|██▌       | 2/8 [00:00<00:02,  2.97it/s]\u001b[A\n","Transfer progress:  38%|███▊      | 3/8 [00:00<00:01,  3.14it/s]\u001b[A\n","Transfer progress:  50%|█████     | 4/8 [00:01<00:01,  3.30it/s]\u001b[A\n","Transfer progress:  62%|██████▎   | 5/8 [00:01<00:00,  3.45it/s]\u001b[A\n","Transfer progress:  75%|███████▌  | 6/8 [00:01<00:00,  3.64it/s]\u001b[A\n","Transfer progress:  88%|████████▊ | 7/8 [00:01<00:00,  3.74it/s]\u001b[A\n","Transfer progress: 100%|██████████| 8/8 [00:02<00:00,  3.68it/s]\n","\n","  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n"," 50%|█████     | 1/2 [00:00<00:00,  6.27it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["loss tensor(5.5361, device='cuda:0', grad_fn=<AddBackward0>)\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|██████████| 2/2 [00:00<00:00,  6.36it/s]\n","100%|██████████| 1/1 [00:02<00:00,  2.51s/it]"],"name":"stderr"},{"output_type":"stream","text":["accuracy tensor(0.6250, device='cuda:0')\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"RbpLB8STKHwm"},"source":["## Evalutae the test data and create submission"]},{"cell_type":"code","metadata":{"id":"W_lnPkBeRVR4","executionInfo":{"status":"ok","timestamp":1607615420255,"user_tz":-60,"elapsed":31864,"user":{"displayName":"François Michel","photoUrl":"","userId":"04680873055823462215"}}},"source":["# Load the test data\n","df_test = load_test(test_path)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"DwKReRkzRVR4","executionInfo":{"status":"ok","timestamp":1607615420255,"user_tz":-60,"elapsed":31851,"user":{"displayName":"François Michel","photoUrl":"","userId":"04680873055823462215"}}},"source":["# Preprocess the test data\n","# out_pre_test = path_to_tweets + 'pre_test.csv'\n","# df_test = preprocess(df_test, out_pre_test)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"nLgqhiISAb0e","executionInfo":{"status":"ok","timestamp":1607615428424,"user_tz":-60,"elapsed":40011,"user":{"displayName":"François Michel","photoUrl":"","userId":"04680873055823462215"}}},"source":["# Tokenize the test data\n","out_csv_path = path_to_tweets + 'token_test.csv'\n","df_test = bert_tokenize_test(df_test, out_csv_path, max_len=TOKEN_LEN)"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WTAwCUW-BO21","executionInfo":{"status":"ok","timestamp":1607615454993,"user_tz":-60,"elapsed":66576,"user":{"displayName":"François Michel","photoUrl":"","userId":"04680873055823462215"}},"outputId":"52e9c8be-3df5-4760-afce-feb3dd8ee66b"},"source":["# Compute and save the prediction\n","out_path = path_to_tweets + 'sub.txt'\n","prediction = get_prediction(model, df_test, BATCH_LEN, out_path, device)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["100%|██████████| 500/500 [00:26<00:00, 18.71it/s]\n"],"name":"stderr"}]}]}