{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import *\n",
    "from helper import *\n",
    "import numpy as np\n",
    "import time\n",
    "from bert import *\n",
    "from data_processing import *\n",
    "import pandas as pd\n",
    "from preprocess import *\n",
    "from sklearn import preprocessing as skp\n",
    "from tweetToVec import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TWEETS = 60000\n",
    "MAX_LEN = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_tweet = '../data/twitter-datasets/'\n",
    "pos_path = path_to_tweet + 'train_pos_full.txt'\n",
    "neg_path = path_to_tweet + 'train_neg_full.txt'\n",
    "test_path = path_to_tweet + 'test_data.txt'\n",
    "\n",
    "df_train = load_train(pos_path, neg_path, NUM_TWEETS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#-----BERT-----\n",
    "#df_train = bert_tokenize_train(df_train, path_to_tweet + 'out_train_testing.csv', max_len=MAX_LEN)\n",
    "#add_padding(df_train)\n",
    "#-----GloVe----\n",
    "#Un-/comment next line to de-/activate preprocessing\n",
    "df_train = preprocess(df_train, path_to_tweet + 'out_pre_train_testing.csv')\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=4, random_state=42, shuffle=True)\n",
    "cross_val = kf.split(df_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------GloVe------\n",
    "df_list = []\n",
    "for s in df_train['tweet']:\n",
    "    df_list.append(tweet_to_vec(s))\n",
    "df_list = skp.scale(df_list)\n",
    "X = np.array(df_list)\n",
    "y = df_train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"df_list_bert = []\\nfor token in df_train['input_ids']:\\n    df_list_bert.append(list(token))\\ndf_list_bert = skp.scale(df_list_bert)\\nX = np.array(df_list_bert)\\ny = df_train['label']\\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-------BERT------\n",
    "\"\"\"df_list_bert = []\n",
    "for token in df_train['input_ids']:\n",
    "    df_list_bert.append(list(token))\n",
    "df_list_bert = skp.scale(df_list_bert)\n",
    "X = np.array(df_list_bert)\n",
    "y = df_train['label']\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---MLP---\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "sizes = [50,100,150]\n",
    "best_acc = 0\n",
    "best_params = []\n",
    "for alpha in np.logspace(-3, -1, 3):\n",
    "    for activation in ['tanh']:\n",
    "        print('alpha = ', alpha)\n",
    "        for size in sizes:\n",
    "            print(\"size =\", size)\n",
    "            clf2 = MLPClassifier(alpha = alpha, solver ='lbfgs', hidden_layer_sizes = (size,size,size), max_iter = 100, random_state = 12)\n",
    "            for train, test in kf.split(X):\n",
    "                #crossval\n",
    "                x_tr = X[train]\n",
    "                x_te = X[test]\n",
    "                y_tr = y.iloc[train]\n",
    "                y_te = y.iloc[test]\n",
    "\n",
    "                start = time.time()\n",
    "                clf2.fit(x_tr, y_tr)\n",
    "                acc = clf2.score(x_te, y_te)\n",
    "                if acc > best_acc:\n",
    "                    best_acc = acc\n",
    "                    best_params = [alpha,activation, size]\n",
    "            print(best_acc)\n",
    "    \n",
    "#0.6430666666666667 [0.039810717055349734, relu, 150] <- BERT\n",
    "#0.6869333333333333 [0.01, relu, 150] <- GloVe, preprocessing\n",
    "#0.6622666666666667 [0.001, relu, 150] <- GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6869333333333333"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_acc_mlp = best_acc\n",
    "best_acc_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c = 0.000010\n",
      "0.6170333333333333\n",
      "[1e-05, 0.0]\n",
      "c = 0.000100\n",
      "0.62715\n",
      "[0.0001, 0.0]\n",
      "c = 0.001000\n",
      "0.6374666666666666\n",
      "[0.001, 0.0]\n",
      "c = 0.010000\n",
      "0.6496\n",
      "[0.01, 0.0]\n",
      "c = 0.100000\n",
      "0.6511\n",
      "[0.1, 0.6]\n",
      "c = 1.000000\n"
     ]
    }
   ],
   "source": [
    "#----LogReg---\n",
    "best_acc = 0\n",
    "best_params = []\n",
    "for c in np.logspace(-5,0,6):\n",
    "    print('c = {:f}'.format(c))\n",
    "    for ratio in (np.arange(11)/10):\n",
    "    #grid-search\n",
    "        \n",
    "        clf3 = LogisticRegression(C=c, penalty = 'elasticnet', n_jobs=-1, solver = 'saga', l1_ratio = ratio)\n",
    "\n",
    "        accuracies = []\n",
    "        for train, test in kf.split(X):\n",
    "            #crossval\n",
    "            x_tr = X[train]\n",
    "            x_te = X[test]\n",
    "            y_tr = y.iloc[train]\n",
    "            y_te = y.iloc[test]\n",
    "\n",
    "            clf3.fit(x_tr, y_tr)\n",
    "\n",
    "            accuracies.append(clf3.score(x_te, y_te))\n",
    "        acc = sum(accuracies)/len(accuracies)\n",
    "        if acc > best_acc :\n",
    "            best_acc = acc \n",
    "            best_params = [c, ratio]\n",
    "    print(best_acc)\n",
    "    print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc_log = best_acc\n",
    "best_params_log = best_params\n",
    "best_acc_log, best_params\n",
    "#(0.6511, [0.1, 0.6]) <- GloVe + preprocess\n",
    "#(0.6352833333333334, [0.01, 0.7]) <- GloVe\n",
    "#(0.6178833333333332, [0.0001, 0.0]) <- bert\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C =  1e-05 pen = l2 loss = hinge\n",
      "0.6103666666666667\n",
      "C =  1e-05 pen = l2 loss = squared_hinge\n",
      "0.6277083333333333\n",
      "C =  0.0001 pen = l2 loss = hinge\n",
      "0.6277083333333333\n",
      "C =  0.0001 pen = l2 loss = squared_hinge\n",
      "0.63925\n",
      "C =  0.001 pen = l2 loss = hinge\n",
      "0.642525\n",
      "C =  0.001 pen = l2 loss = squared_hinge\n",
      "0.6475250000000001\n",
      "C =  0.01 pen = l2 loss = hinge\n",
      "0.6481\n",
      "C =  0.01 pen = l2 loss = squared_hinge\n",
      "0.6481\n",
      "C =  0.1 pen = l2 loss = hinge\n",
      "0.6491333333333333\n",
      "C =  0.1 pen = l2 loss = squared_hinge\n",
      "0.6491333333333333\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "best_acc = 0\n",
    "\n",
    "for c in np.logspace(-5,-1, 5):\n",
    "    for penalty in ['l2']:\n",
    "        for loss in ['hinge', 'squared_hinge']:\n",
    "            print('C = ', c, 'pen =', penalty, 'loss =', loss)\n",
    "            clf4 = LinearSVC(C = c, penalty = penalty, dual=True, loss = loss, max_iter=100000, random_state = 42)\n",
    "\n",
    "            accuracies = []\n",
    "            for train, test in kf.split(X):\n",
    "                #Cross-validation\n",
    "                x_tr = X[train]\n",
    "                x_te = X[test]\n",
    "                y_tr = y.iloc[train]\n",
    "                y_te = y.iloc[test]\n",
    "                x_tr_l = []\n",
    "                x_te_l = []\n",
    "\n",
    "                clf4.fit(x_tr, y_tr)\n",
    "\n",
    "                accuracies.append(clf4.score(x_te, y_te))\n",
    "                acc = sum(accuracies)/len(accuracies)\n",
    "                if acc > best_acc :\n",
    "                    best_acc = acc \n",
    "                    best_params = [c,penalty, loss]\n",
    "            print(best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc_svm = best_acc\n",
    "best_params_svm = best_params\n",
    "best_acc_svm, best_params_svm\n",
    "#(0.6533333333333333, [0.1, 'l2', 'hinge']) GloVe + preprocessing\n",
    "#0.64 BERT\n",
    "#(0.636, [0.1, 'l2', 'hinge']) GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.ylim(0.6, 0.7)\n",
    "plt.bar(['svm', 'mlp', 'log_reg'],[best_acc_svm, best_acc_mlp, best_acc_log], )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
